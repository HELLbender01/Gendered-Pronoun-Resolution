{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-09-05T17:37:06.788910Z",
     "iopub.status.busy": "2020-09-05T17:37:06.788127Z",
     "iopub.status.idle": "2020-09-05T17:37:06.807923Z",
     "shell.execute_reply": "2020-09-05T17:37:06.808560Z"
    },
    "papermill": {
     "duration": 0.034823,
     "end_time": "2020-09-05T17:37:06.808747",
     "exception": false,
     "start_time": "2020-09-05T17:37:06.773924",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/gap-dataloaders/dataloaders1.pth\n",
      "/kaggle/input/gap-dataloaders/test_loader.pth\n",
      "/kaggle/input/gap-dataloaders/test_loader(1).pth\n",
      "/kaggle/input/gap-dataloaders/dataloaders2.pth\n",
      "/kaggle/input/gap-dataloaders/dataloaders.pth\n",
      "/kaggle/input/gendered-pronoun-resolution/sample_submission_stage_1.csv\n",
      "/kaggle/input/gendered-pronoun-resolution/test_stage_1.tsv\n",
      "/kaggle/input/gendered-pronoun-resolution/sample_submission_stage_2.csv\n",
      "/kaggle/input/gendered-pronoun-resolution/test_stage_2.tsv\n",
      "/kaggle/input/gendered-model/test_loader.pth\n",
      "/kaggle/input/gendered-model/dataloaders2.pth\n",
      "/kaggle/input/gendered-model/model1.pth\n",
      "/kaggle/input/gapvalidation/LICENSE\n",
      "/kaggle/input/gapvalidation/CONTRIBUTING.md\n",
      "/kaggle/input/gapvalidation/gap-development.tsv\n",
      "/kaggle/input/gapvalidation/gap-validation.tsv\n",
      "/kaggle/input/gapvalidation/README.md\n",
      "/kaggle/input/gapvalidation/gap-test.tsv\n",
      "/kaggle/input/gapvalidation/constants.py\n",
      "/kaggle/input/gapvalidation/gap_scorer.py\n",
      "/kaggle/input/gapvalidation/repository/google-research-datasets-gap-coreference-83135f2/LICENSE\n",
      "/kaggle/input/gapvalidation/repository/google-research-datasets-gap-coreference-83135f2/CONTRIBUTING.md\n",
      "/kaggle/input/gapvalidation/repository/google-research-datasets-gap-coreference-83135f2/gap-development.tsv\n",
      "/kaggle/input/gapvalidation/repository/google-research-datasets-gap-coreference-83135f2/gap-validation.tsv\n",
      "/kaggle/input/gapvalidation/repository/google-research-datasets-gap-coreference-83135f2/README.md\n",
      "/kaggle/input/gapvalidation/repository/google-research-datasets-gap-coreference-83135f2/gap-test.tsv\n",
      "/kaggle/input/gapvalidation/repository/google-research-datasets-gap-coreference-83135f2/constants.py\n",
      "/kaggle/input/gapvalidation/repository/google-research-datasets-gap-coreference-83135f2/gap_scorer.py\n",
      "/kaggle/input/bert-base-uncased/vocab.txt\n",
      "/kaggle/input/bert-base-uncased/pytorch_model.bin\n",
      "/kaggle/input/bert-base-uncased/config.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.006989,
     "end_time": "2020-09-05T17:37:06.823845",
     "exception": false,
     "start_time": "2020-09-05T17:37:06.816856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the PyTorch BERT model as well as the GAP dataset and the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-09-05T17:37:06.844395Z",
     "iopub.status.busy": "2020-09-05T17:37:06.843807Z",
     "iopub.status.idle": "2020-09-05T17:37:16.007288Z",
     "shell.execute_reply": "2020-09-05T17:37:16.006280Z"
    },
    "papermill": {
     "duration": 9.176719,
     "end_time": "2020-09-05T17:37:16.007426",
     "exception": false,
     "start_time": "2020-09-05T17:37:06.830707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"SEED\"] = \"420\"\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, BertConfig\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.006993,
     "end_time": "2020-09-05T17:37:16.021875",
     "exception": false,
     "start_time": "2020-09-05T17:37:16.014882",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Loading the csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:37:16.047052Z",
     "iopub.status.busy": "2020-09-05T17:37:16.046388Z",
     "iopub.status.idle": "2020-09-05T17:37:16.260014Z",
     "shell.execute_reply": "2020-09-05T17:37:16.259297Z"
    },
    "papermill": {
     "duration": 0.231097,
     "end_time": "2020-09-05T17:37:16.260133",
     "exception": false,
     "start_time": "2020-09-05T17:37:16.029036",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/gapvalidation/gap-test.tsv\", delimiter=\"\\t\")\n",
    "df_val = pd.read_csv(\"/kaggle/input/gapvalidation/gap-validation.tsv\", delimiter=\"\\t\")\n",
    "df_test = pd.read_csv(\"/kaggle/input/gapvalidation/gap-development.tsv\", delimiter=\"\\t\")\n",
    "test_2 = pd.read_csv(\"/kaggle/input/gendered-pronoun-resolution/test_stage_2.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "PRETRAINED_MODEL_NAME = 'bert-large-uncased'\n",
    "\n",
    "bert_path = \"../input/bert-base-uncased/\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "pad_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:37:16.283401Z",
     "iopub.status.busy": "2020-09-05T17:37:16.282659Z",
     "iopub.status.idle": "2020-09-05T17:37:17.284843Z",
     "shell.execute_reply": "2020-09-05T17:37:17.284216Z"
    },
    "papermill": {
     "duration": 1.017659,
     "end_time": "2020-09-05T17:37:17.284974",
     "exception": false,
     "start_time": "2020-09-05T17:37:16.267315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conver_lower(df):\n",
    "    df['Text'] = df.apply(lambda row: row['Text'].lower(), axis = 1)\n",
    "    df['A'] = df.apply(lambda row: row['A'].lower(), axis = 1)\n",
    "    df['B'] = df.apply(lambda row: row['B'].lower(), axis = 1)\n",
    "    df['Pronoun'] = df.apply(lambda row: row['Pronoun'].lower(), axis = 1)\n",
    "    return df\n",
    "df_train = conver_lower(df_train)\n",
    "df_test = conver_lower(df_test)\n",
    "df_val = conver_lower(df_val)\n",
    "test_2 = conver_lower(test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007081,
     "end_time": "2020-09-05T17:37:17.299402",
     "exception": false,
     "start_time": "2020-09-05T17:37:17.292321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions to extract choices and turning trainable feature off (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:37:17.334611Z",
     "iopub.status.busy": "2020-09-05T17:37:17.332653Z",
     "iopub.status.idle": "2020-09-05T17:37:17.335402Z",
     "shell.execute_reply": "2020-09-05T17:37:17.335859Z"
    },
    "papermill": {
     "duration": 0.029385,
     "end_time": "2020-09-05T17:37:17.335979",
     "exception": false,
     "start_time": "2020-09-05T17:37:17.306594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer.add_tokens(['[A]', '[B]', '[P]'])\n",
    "def insert_tag(row):\n",
    "    to_be_inserted = sorted([\n",
    "        (row[\"A-offset\"], \" [A] \"),\n",
    "        (row[\"B-offset\"], \" [B] \"),\n",
    "        (row[\"Pronoun-offset\"], \" [P] \")\n",
    "    ], key=lambda x: x[0], reverse=True)\n",
    "    text = row[\"Text\"]\n",
    "    for offset, tag in to_be_inserted:\n",
    "        text = text[:offset] + tag + text[offset:]\n",
    "    return text\n",
    "\n",
    "def tokenize(text, tokenizer):\n",
    "    entries = {}\n",
    "    final_tokens = []\n",
    "    for token in tokenizer.tokenize(text):\n",
    "        if token in (\"[A]\", \"[B]\", \"[P]\"):\n",
    "            entries[token] = len(final_tokens)\n",
    "            continue\n",
    "        final_tokens.append(token)\n",
    "    return final_tokens, (entries[\"[A]\"], entries[\"[B]\"], entries[\"[P]\"])\n",
    "\n",
    "def target(row):\n",
    "    if int(row['A-coref']) == 1:\n",
    "        return 0\n",
    "    elif int(row['B-coref']) == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "\"\"\"\n",
    "The lower part was taken from \n",
    "            [PyTorch] BERT + EndpointSpanExtractor + KFold\n",
    "\"\"\"\n",
    "def children(m):\n",
    "    return m if isinstance(m, (list, tuple)) else list(m.children())\n",
    "\n",
    "def set_trainable_attr(m, b):\n",
    "    m.trainable = b\n",
    "    for p in m.parameters():\n",
    "        p.requires_grad = b\n",
    "\n",
    "def apply_leaf(m, f):\n",
    "    c = children(m)\n",
    "    if isinstance(m, nn.Module):\n",
    "        f(m)\n",
    "    if len(c) > 0:\n",
    "        for l in c:\n",
    "            apply_leaf(l, f)\n",
    "            \n",
    "def set_trainable(l, b):\n",
    "    apply_leaf(l, lambda m: set_trainable_attr(m, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.007298,
     "end_time": "2020-09-05T17:37:17.350457",
     "exception": false,
     "start_time": "2020-09-05T17:37:17.343159",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Torch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:37:17.407598Z",
     "iopub.status.busy": "2020-09-05T17:37:17.382843Z",
     "iopub.status.idle": "2020-09-05T17:38:05.596630Z",
     "shell.execute_reply": "2020-09-05T17:38:05.597924Z"
    },
    "papermill": {
     "duration": 48.240553,
     "end_time": "2020-09-05T17:38:05.598143",
     "exception": false,
     "start_time": "2020-09-05T17:37:17.357590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:06<00:00, 321.08it/s]\n",
      "100%|██████████| 454/454 [00:01<00:00, 348.10it/s]\n",
      "100%|██████████| 2000/2000 [00:05<00:00, 340.32it/s]\n",
      "100%|██████████| 12359/12359 [00:33<00:00, 372.18it/s]\n"
     ]
    }
   ],
   "source": [
    "class modified_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        p_text = []\n",
    "        offsets = []\n",
    "        at_mask = []\n",
    "        self.y_lst = df[['A-coref', 'B-coref']].apply(lambda row: target(row), axis = 1)\n",
    "        for row in tqdm(range(len(df))):\n",
    "            tokens, offset = tokenize(insert_tag(df.iloc[row]), tokenizer)\n",
    "            bla = tokenizer.encode_plus(tokens, max_length = pad_len, pad_to_max_length = True, return_token_type_ids = False)\n",
    "            p_text.append(bla['input_ids'])\n",
    "            at_mask.append(bla['attention_mask'])\n",
    "            offsets.append(offset)\n",
    "        self.p_text = torch.tensor(p_text)\n",
    "        self.offsets = torch.tensor(offsets)\n",
    "        self.at_mask = torch.tensor(at_mask)\n",
    "        return \n",
    "    def __len__(self):\n",
    "        return len(self.p_text)\n",
    "    def __getitem__(self,item):\n",
    "        return self.p_text[item], self.y_lst[item], self.offsets[item], self.at_mask[item]\n",
    "\n",
    "class modified_dataset_test(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer):\n",
    "        p_text = []\n",
    "        offsets = []\n",
    "        at_mask = []\n",
    "        for row in tqdm(range(len(df))):\n",
    "            tokens, offset = tokenize(insert_tag(df.iloc[row]), tokenizer)\n",
    "            bla = tokenizer.encode_plus(tokens, max_length = pad_len, pad_to_max_length = True, return_token_type_ids = False)\n",
    "            p_text.append(bla['input_ids'])\n",
    "            at_mask.append(bla['attention_mask'])\n",
    "            offsets.append(offset)\n",
    "        self.p_text = torch.tensor(p_text)\n",
    "        self.offsets = torch.tensor(offsets)\n",
    "        self.at_mask = torch.tensor(at_mask)\n",
    "        return  \n",
    "    def __len__(self):\n",
    "        return len(self.p_text)\n",
    "    def __getitem__(self,item):\n",
    "        return self.p_text[item], self.offsets[item], self.at_mask[item]\n",
    " \n",
    "def collate_fun(batch):\n",
    "    tmp_lst = list(zip(*batch))\n",
    "    return torch.stack(tmp_lst[0], axis = 0), torch.tensor(tmp_lst[1]), torch.stack(tmp_lst[2], axis = 0), torch.stack(tmp_lst[3], axis = 0)\n",
    "\n",
    "def collate_fun2(batch):\n",
    "    tmp_lst = list(zip(*batch))\n",
    "    return torch.stack(tmp_lst[0], axis = 0), torch.stack(tmp_lst[1], axis = 0), torch.stack(tmp_lst[2], axis = 0)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "        modified_dataset(df_train, tokenizer),\n",
    "        batch_size=18,\n",
    "        collate_fn=collate_fun,\n",
    "        shuffle=True,\n",
    "        drop_last=True,\n",
    "        num_workers=2)\n",
    "val_loader = DataLoader(\n",
    "        modified_dataset(df_val, tokenizer),\n",
    "        batch_size=30,\n",
    "        collate_fn=collate_fun,\n",
    "        shuffle=False,\n",
    "        num_workers=2)\n",
    "test_loader = DataLoader(\n",
    "        modified_dataset(df_test, tokenizer),\n",
    "        batch_size=30,\n",
    "        collate_fn=collate_fun,\n",
    "        shuffle=False,\n",
    "        num_workers=2)\n",
    "test_2_loader = DataLoader(\n",
    "        modified_dataset_test(test_2, tokenizer),\n",
    "        batch_size=30,\n",
    "        collate_fn=collate_fun2,\n",
    "        shuffle=False,\n",
    "        num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.051212,
     "end_time": "2020-09-05T17:38:05.700461",
     "exception": false,
     "start_time": "2020-09-05T17:38:05.649249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Saving the dataloaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:38:06.218234Z",
     "iopub.status.busy": "2020-09-05T17:38:06.217393Z",
     "iopub.status.idle": "2020-09-05T17:38:06.312722Z",
     "shell.execute_reply": "2020-09-05T17:38:06.315858Z"
    },
    "papermill": {
     "duration": 0.567902,
     "end_time": "2020-09-05T17:38:06.316057",
     "exception": false,
     "start_time": "2020-09-05T17:38:05.748155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPU = torch.cuda.is_available()\n",
    "torch.save({'train_loader':train_loader,\n",
    "            'test_loader':test_loader,\n",
    "            'val_loader':val_loader}, 'dataloader_new.pth')\n",
    "torch.save({'test_dataloader':test_2_loader},'test_loader.pth')\n",
    "# train_loader, test_loader, val_loader = torch.load('/kaggle/input/gap-dataloaders/dataloaders2.pth').values()\n",
    "# test_2_loader = torch.load('/kaggle/input/gap-dataloaders/test_loader(1).pth')['test_dataloader_174']"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.046716,
     "end_time": "2020-09-05T17:38:06.414348",
     "exception": false,
     "start_time": "2020-09-05T17:38:06.367632",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:38:06.521573Z",
     "iopub.status.busy": "2020-09-05T17:38:06.520765Z",
     "iopub.status.idle": "2020-09-05T17:38:06.528978Z",
     "shell.execute_reply": "2020-09-05T17:38:06.530069Z"
    },
    "papermill": {
     "duration": 0.059674,
     "end_time": "2020-09-05T17:38:06.530220",
     "exception": false,
     "start_time": "2020-09-05T17:38:06.470546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class bert(nn.Module):\n",
    "    def __init__(self, bert_path):\n",
    "        super().__init__()\n",
    "        BERT = BertModel.from_pretrained(bert_path, config = BertConfig.from_pretrained(bert_path, output_hidden_states = True))\n",
    "        self.BERT = BERT\n",
    "        self.fc = nn.Sequential(nn.BatchNorm1d(self.BERT.config.hidden_size * 3),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(self.BERT.config.hidden_size * 3, 600),\n",
    "                                nn.BatchNorm1d(600),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(600, 600),\n",
    "                                nn.BatchNorm1d(600),\n",
    "                                nn.Dropout(0.4),\n",
    "                                nn.Linear(600,3))\n",
    "        \n",
    "    def forward(self, token, at_mask, offsets, layer):\n",
    "        out = self.BERT(token, attention_mask = at_mask)[2][layer]\n",
    "        out_lst = []\n",
    "        for j in range(out.shape[0]):\n",
    "            out_lst.append(torch.stack([torch.tensor(out[j,offsets[j,0]]),torch.tensor(out[j,offsets[j,1]]),torch.tensor(out[j,offsets[j,2]])] , dim = 0) )\n",
    "        out_lst = torch.stack([word_embedding for word_embedding in out_lst], dim = 0)\n",
    "        out = out_lst.reshape(out_lst.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n",
    "def create_model(df_len,epoch_len):        \n",
    "    model = bert(bert_path)\n",
    "    criteria = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), eps = 1e-06, lr = 1e-4)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=df_len*epoch_len)\n",
    "    return model, criteria, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.035837,
     "end_time": "2020-09-05T17:38:06.600976",
     "exception": false,
     "start_time": "2020-09-05T17:38:06.565139",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:38:06.690230Z",
     "iopub.status.busy": "2020-09-05T17:38:06.689271Z",
     "iopub.status.idle": "2020-09-05T17:47:04.549111Z",
     "shell.execute_reply": "2020-09-05T17:47:04.549690Z"
    },
    "papermill": {
     "duration": 537.913852,
     "end_time": "2020-09-05T17:47:04.549850",
     "exception": false,
     "start_time": "2020-09-05T17:38:06.635998",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/111 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 111/111 [00:22<00:00,  4.83it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104.20628222823143 tensor(1191, device='cuda:0')     tensor(298, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.10it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.1304906308651 tensor(1415, device='cuda:0')     tensor(301, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.07it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.40701606869698 tensor(1445, device='cuda:0')     tensor(308, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.10it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.67it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.81449657678604 tensor(1502, device='cuda:0')     tensor(315, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.05it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.66it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.28550009429455 tensor(1537, device='cuda:0')     tensor(310, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.10it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.66it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.8309333473444 tensor(1578, device='cuda:0')     tensor(316, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.06it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.63it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64.39176070690155 tensor(1552, device='cuda:0')     tensor(320, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.09it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.543243795633316 tensor(1571, device='cuda:0')     tensor(322, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:22<00:00,  5.03it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.63it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63.604194551706314 tensor(1565, device='cuda:0')     tensor(315, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.07it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.66it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.72537903487682 tensor(1588, device='cuda:0')     tensor(314, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.06it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.59it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.533024087548256 tensor(1562, device='cuda:0')     tensor(316, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:22<00:00,  5.03it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.66it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.81847859919071 tensor(1596, device='cuda:0')     tensor(319, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.07it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.61it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.32688665390015 tensor(1584, device='cuda:0')     tensor(316, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:22<00:00,  5.03it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.69425509870052 tensor(1573, device='cuda:0')     tensor(316, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.06it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.46196522563696 tensor(1624, device='cuda:0')     tensor(318, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:22<00:00,  5.03it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.11275500059128 tensor(1601, device='cuda:0')     tensor(321, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.07it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.65it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.37442408502102 tensor(1621, device='cuda:0')     tensor(315, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.05it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.56it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.01405081152916 tensor(1622, device='cuda:0')     tensor(320, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.05it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]\n",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.13203938305378 tensor(1633, device='cuda:0')     tensor(327, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:21<00:00,  5.05it/s]\n",
      "100%|██████████| 16/16 [00:04<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50.758082062006 tensor(1630, device='cuda:0')     tensor(317, device='cuda:0')  out of  480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "epoch_len = 20\n",
    "model, criteria, optimizer, scheduler = create_model(len(df_train), epoch_len)\n",
    "set_trainable(model.BERT, False)\n",
    "aaa = 0\n",
    "for t in range(epoch_len):\n",
    "    tot_loss = 0\n",
    "    correct_train = 0\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    model = model.train()\n",
    "    \n",
    "    if GPU:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    for item in tqdm(train_loader):\n",
    "        \n",
    "        token = item[0]\n",
    "        at_mask = item[3]\n",
    "        offsets = item[2]\n",
    "        target = item[1]\n",
    "        if GPU:\n",
    "            token = token.cuda()\n",
    "            at_mask = at_mask.cuda()\n",
    "            target = target.cuda()\n",
    "            offsets = offsets.cuda()\n",
    "            \n",
    "        output = model(token, at_mask, offsets, -2)\n",
    "        loss = criteria(output, target)\n",
    "        tot_loss += loss.item()\n",
    "        correct_train += torch.sum(torch.max(torch.nn.functional.softmax(output, dim = 1), dim = 1)[1] == target)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        \n",
    "        if GPU:\n",
    "            model = model.cuda()            \n",
    "        for item in tqdm(val_loader):\n",
    "            token = item[0]\n",
    "            at_mask = item[3]\n",
    "            offsets = item[2]\n",
    "            target = item[1]\n",
    "            \n",
    "            if GPU:\n",
    "                token = token.cuda()\n",
    "                at_mask = at_mask.cuda()\n",
    "                offsets = offsets.cuda()\n",
    "                target = target.cuda()\n",
    "                \n",
    "            output = model(token, at_mask, offsets, -2)\n",
    "            val_correct += torch.sum(torch.max(torch.nn.functional.softmax(output, dim = 1), dim = 1)[1] == target)\n",
    "        if val_correct > aaa:\n",
    "            bst_model = model\n",
    "            aaa = val_correct\n",
    "    print(tot_loss, correct_train,\"   \", val_correct,\" out of \", len(val_loader)*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.191344,
     "end_time": "2020-09-05T17:47:04.937035",
     "exception": false,
     "start_time": "2020-09-05T17:47:04.745691",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:47:05.644114Z",
     "iopub.status.busy": "2020-09-05T17:47:05.643174Z",
     "iopub.status.idle": "2020-09-05T17:47:05.647795Z",
     "shell.execute_reply": "2020-09-05T17:47:05.649470Z"
    },
    "papermill": {
     "duration": 0.30086,
     "end_time": "2020-09-05T17:47:05.649673",
     "exception": false,
     "start_time": "2020-09-05T17:47:05.348813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(df, dataloader, model):\n",
    "    tmp_array = np.zeros((len(df), 3))\n",
    "    with torch.no_grad():\n",
    "        model = model.eval()\n",
    "        if GPU:\n",
    "            model = model.cuda()\n",
    "        \n",
    "        j = 0\n",
    "        for item in tqdm(dataloader):\n",
    "            \n",
    "            token = item[0]\n",
    "            at_mask = item[2]\n",
    "            offsets = item[1]\n",
    "\n",
    "            if GPU:\n",
    "                token = token.cuda()\n",
    "                at_mask = at_mask.cuda()\n",
    "                offsets = offsets.cuda()\n",
    "            \n",
    "            output = model(token, at_mask, offsets, -2)\n",
    "            for zz in output.cpu():\n",
    "                tmp_array[j] = zz\n",
    "                j+=1\n",
    "            \n",
    "    return tmp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:47:06.466056Z",
     "iopub.status.busy": "2020-09-05T17:47:06.464935Z",
     "iopub.status.idle": "2020-09-05T17:49:03.304758Z",
     "shell.execute_reply": "2020-09-05T17:49:03.305305Z"
    },
    "papermill": {
     "duration": 117.233329,
     "end_time": "2020-09-05T17:49:03.305464",
     "exception": false,
     "start_time": "2020-09-05T17:47:06.072135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/412 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "100%|██████████| 412/412 [01:56<00:00,  3.53it/s]\n"
     ]
    }
   ],
   "source": [
    "a = predict(test_2, test_2_loader, bst_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:49:03.716114Z",
     "iopub.status.busy": "2020-09-05T17:49:03.715531Z",
     "iopub.status.idle": "2020-09-05T17:49:04.096763Z",
     "shell.execute_reply": "2020-09-05T17:49:04.095981Z"
    },
    "papermill": {
     "duration": 0.589425,
     "end_time": "2020-09-05T17:49:04.096900",
     "exception": false,
     "start_time": "2020-09-05T17:49:03.507475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bla = test_2[['ID']].merge(pd.DataFrame(torch.nn.functional.softmax(torch.tensor(a), dim = 1).numpy()), left_index=True, right_index=True).set_index('ID')\n",
    "bla.columns = ['A', 'B', 'NEITHER']\n",
    "bla.to_csv('sbmsn2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:49:04.505064Z",
     "iopub.status.busy": "2020-09-05T17:49:04.504452Z",
     "iopub.status.idle": "2020-09-05T17:49:05.218798Z",
     "shell.execute_reply": "2020-09-05T17:49:05.219632Z"
    },
    "papermill": {
     "duration": 0.920238,
     "end_time": "2020-09-05T17:49:05.219852",
     "exception": false,
     "start_time": "2020-09-05T17:49:04.299614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type bert. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save({'model':bst_model}, 'model1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-05T17:49:05.822974Z",
     "iopub.status.busy": "2020-09-05T17:49:05.822289Z",
     "iopub.status.idle": "2020-09-05T17:49:08.649084Z",
     "shell.execute_reply": "2020-09-05T17:49:08.647948Z"
    },
    "papermill": {
     "duration": 3.136354,
     "end_time": "2020-09-05T17:49:08.649223",
     "exception": false,
     "start_time": "2020-09-05T17:49:05.512869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tst_model = torch.load('/kaggle/input/gendered-model/model1.pth')['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.288326,
     "end_time": "2020-09-05T17:49:09.147536",
     "exception": false,
     "start_time": "2020-09-05T17:49:08.859210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 727.875396,
   "end_time": "2020-09-05T17:49:10.062016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-05T17:37:02.186620",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
